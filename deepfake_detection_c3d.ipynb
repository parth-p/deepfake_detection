{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data1\n",
    "from torch.utils import data\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorboardX import SummaryWriter\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class C3D(nn.Module):\n",
    "    def __init__(self, img_dim, frames,dropout):\n",
    "        super(C3D, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv3d(3, 32, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
    "        self.bn1 = nn.BatchNorm3d(32)\n",
    "\n",
    "        self.conv2 = nn.Conv3d(32, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
    "        self.bn2 = nn.BatchNorm3d(64)\n",
    "        \n",
    "        self.conv3a = nn.Conv3d(64, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv3b = nn.Conv3d(64, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool3 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "        self.bn3 = nn.BatchNorm3d(64)\n",
    "        \n",
    "        self.conv4a = nn.Conv3d(64, 128, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv4b = nn.Conv3d(128, 128, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool4 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "        self.bn4 = nn.BatchNorm3d(128)\n",
    "        \n",
    "        self.conv5a = nn.Conv3d(128, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv5b = nn.Conv3d(256, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool5 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(0, 1, 1))\n",
    "        \n",
    "        dim_shape = new_output_shape(num_of_maxpool_2=5, shape=img_dim)\n",
    "        channel_shape = new_channel_shape(frames=frames) # As first time channel is not modified\n",
    "        self.fc_conv = nn.Conv3d(256, 2, kernel_size=(channel_shape, dim_shape, dim_shape))\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.type(torch.cuda.FloatTensor)\n",
    "        x = x.permute(0,4,1,2,3)\n",
    "\n",
    "        h = self.relu(self.conv1(x))\n",
    "        h = self.bn1(h)\n",
    "        h = self.pool1(h)\n",
    "        h = self.dropout(h)\n",
    "        \n",
    "        h = self.relu(self.conv2(h))\n",
    "        h = self.bn2(h)\n",
    "        h = self.pool2(h)\n",
    "        h = self.dropout(h)\n",
    "\n",
    "        h = self.relu(self.conv3a(h))\n",
    "        h = self.relu(self.conv3b(h))\n",
    "        h = self.bn3(h)\n",
    "        h = self.pool3(h)\n",
    "        h = self.dropout(h)\n",
    "        \n",
    "        h = self.relu(self.conv4a(h))\n",
    "        h = self.relu(self.conv4b(h))\n",
    "        h = self.bn4(h)\n",
    "        h = self.pool4(h)\n",
    "        h = self.dropout(h)\n",
    "        \n",
    "        h = self.relu(self.conv5a(h))\n",
    "        h = self.relu(self.conv5b(h))\n",
    "        h = self.pool5(h)\n",
    "        h = self.fc_conv(h)\n",
    "        \n",
    "        logits = h.view(x.shape[0],-1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resize and crop image, and stack them together alongg with label y=0 or 1 if orignal or fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "class Dataload_3D_CNN(data.Dataset):\n",
    "    def __init__(self, data_path, transform=None):\n",
    "        self.transform = transform\n",
    "        self.folders = data_path\n",
    "\n",
    "    def read_images(self, data_path, use_transform):\n",
    "        X = []\n",
    "        for i in os.listdir(data_path):\n",
    "            image = Image.open(os.path.join(data_path,i))\n",
    "            \n",
    "            if use_transform is not None:\n",
    "                image = use_transform(image)\n",
    "            image = torch.from_numpy(np.asarray(image))\n",
    "            X.append(image)\n",
    "        X = torch.stack(X, dim=0)\n",
    "        return X\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_path = os.path.join(self.folders,os.listdir(self.folders)[index])\n",
    "        \n",
    "        X = self.read_images(data_path, self.transform)\n",
    "        y = 1\n",
    "        if 'orig' in data_path:\n",
    "            y = 0\n",
    "        return X, torch.from_numpy(np.array(y)).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRANSFORM_IMG = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(256),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = './data/train/'\n",
    "train_data = Dataload_3D_CNN(train_path, transform=TRANSFORM_IMG)\n",
    "val_path = './data/val/'\n",
    "val_data = Dataload_3D_CNN(val_path, transform=TRANSFORM_IMG)\n",
    "\n",
    "cnn3d = C3D(img_dim=256, frames=10, dropout=0.4)\n",
    "optimizer = torch.optim.Adam(cnn3d.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "batch_size = 8\n",
    "learning_rate = 1e-4\n",
    "log_interval = 10\n",
    "img_x, img_y = 256,256\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "fc_hidden1, fc_hidden2 = 256, 256\n",
    "dropout = 0.0\n",
    "begin_frame, end_frame, skip_frame = 1, 10, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(log_interval, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    scores = []\n",
    "    N_count = 0\n",
    "    for batch_idx, (X, y) in enumerate(train_loader):\n",
    "        N_count += X.size(0)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = F.cross_entropy(output, y)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        y_pred = torch.max(output, 1)[1]\n",
    "        step_score = accuracy_score(y.data.squeeze().numpy(), y_pred.data.squeeze().numpy())\n",
    "        scores.append(step_score)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return np.mean(losses), np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    train_losses, train_scores = train(log_interval, cnn3d, device, train_loader, optimizer, epoch)\n",
    "    print(\"Training Loss : \"+str(train_losses))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
